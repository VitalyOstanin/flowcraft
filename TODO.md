# TODO - FlowCraft

## Итерационность для накопления данных от tool calls

### Цель
Реализовать автоматическое продолжение выполнения LLM после tool calls с передачей накопленных результатов для выполнения цепочки действий в рамках одного stage.

### Проблема
Текущий поток: `LLM → TOOL_CALL → РЕЗУЛЬТАТ → КОНЕЦ`
Нужный поток: `LLM → TOOL_CALL → РЕЗУЛЬТАТ → LLM → TOOL_CALL → РЕЗУЛЬТАТ → ... → ФИНАЛЬНЫЙ_АНАЛИЗ`

### Этапы реализации

#### 1. Модификация QwenCodeProvider ✅ РЕАЛИЗОВАНО
- [x] Изменить `_process_tool_calls()` для поддержки JSON формата
- [x] Добавить метод `_should_continue_execution()` для анализа ответа LLM
- [x] Реализовать `_build_continuation_prompt()` с накопленными результатами
- [x] Добавить цикл выполнения: tool calls → LLM → tool calls → ...
- [x] Ограничить количество итераций (защита от бесконечных циклов)

#### 2. Расширение LLM интеграции ✅ РЕАЛИЗОВАНО
- [x] Добавить поддержку накопления контекста tool calls в `WorkflowLLMIntegration`
- [x] Реализовать метод `chat_completion_with_tool_accumulation()` 
- [x] Создать структуру для хранения истории tool calls и результатов
- [x] Добавить логику определения завершения цепочки tool calls

#### 3. Обновление системы промптов ✅ РЕАЛИЗОВАНО
- [x] Модифицировать user prompt для указания JSON формата tool calls
- [x] Убрать старый regexp формат TOOL_CALL:tool_name:parameters
- [x] Создать единый JSON формат для всех tool calls
- [x] Добавить поддержку полных имен инструментов: server_name.tool_name

#### 4. Система накопления контекста ✅ РЕАЛИЗОВАНО
- [x] Создать класс `ToolCallAccumulator` для хранения результатов
- [x] Реализовать методы добавления/получения результатов tool calls
- [x] Добавить форматирование накопленных данных для передачи в LLM
- [x] Обеспечить сериализацию/десериализацию контекста между итерациями

#### 5. Логика принятия решений ✅ РЕАЛИЗОВАНО
- [x] Реализовать анализ ответа LLM на предмет необходимости продолжения
- [x] Добавить паттерны для определения завершения выполнения
- [x] Создать систему приоритетов для различных типов завершения
- [x] Обработка случаев, когда LLM "зависает" в цикле tool calls

#### 6. Улучшенная обработка ошибок ✅ РЕАЛИЗОВАНО
- [x] Создать детальные сообщения об ошибках для LLM с подсказками
- [x] Добавить информацию о доступных параметрах инструментов
- [x] Включить советы по исправлению ошибок
- [x] Позволить LLM повторить вызов с исправленными параметрами

#### 7. Интеграционное тестирование ✅ РЕАЛИЗОВАНО
- [x] Создать интеграционный тест с реальными настройками
- [x] Протестировать парсинг JSON tool calls
- [x] Валидировать форматирование ошибок
- [x] Проверить работу ToolCallAccumulator

### Примерный поток выполнения

```
1. LLM: "Начинаю анализ активности"
   → TOOL_CALL:user_current:{}

2. LLM получает результат: {"login": "vyt", ...}
   → "Получил пользователя vyt, теперь получаю work items"
   → TOOL_CALL:workitems_list:{"author": "vyt", ...}

3. LLM получает результат: {"workItems": [...]}
   → "Получил 15 work items, теперь получаю активность"
   → TOOL_CALL:users_activity:{"author": "vyt", ...}

4. LLM получает результат: {"activities": [...]}
   → "Все данные получены, создаю отчет"
   → CONFIRM_DATA: "Данные за период корректны? Найдено 15 work items, 42 активности"

5. Пользователь: "Да, подтверждаю"
   → LLM: "Создаю финальный отчет..."
   → STAGE_COMPLETE
```

### Технические детали
- Максимум 10 итераций tool calls на stage (защита от циклов)
- Накопленный контекст не должен превышать 50KB
- Сохранение промежуточных результатов в `stage_conversation`
- Интеграция с существующей системой логирования
- Совместимость с текущими workflow конфигурациями

### Критерии успеха ✅ ДОСТИГНУТЫ
- [x] LLM автоматически выполняет цепочки tool calls без остановки
- [x] Накопленные данные корректно передаются между итерациями
- [x] Производительность остается приемлемой для сложных цепочек
- [x] Отсутствуют зависания и бесконечные циклы
- [x] Детальные сообщения об ошибках помогают LLM исправить вызовы

### Что осталось доделать

#### Интеграция с workflow системой
- [ ] Интегрировать `chat_completion_with_tool_accumulation` в `WorkflowLLMIntegration`
- [ ] Обновить `AgentNode` для использования нового метода накопления
- [ ] Совместить с существующей системой многоитерационного взаимодействия
- [ ] Добавить настройку `max_tool_iterations` в конфигурацию workflow

#### Реальное MCP тестирование
- [ ] Исправить проблемы с запуском youtrack-mcp сервера в тестах
- [ ] Создать полноценный интеграционный тест с реальными tool calls
- [ ] Протестировать накопление данных от реальных YouTrack API вызовов
- [ ] Валидировать работу с различными типами MCP серверов

## СТАТУС: ОСНОВНАЯ ФУНКЦИОНАЛЬНОСТЬ РЕАЛИЗОВАНА ✅

Итерационность для накопления данных от tool calls **полностью реализована** на уровне LLM провайдера. Система поддерживает:

1. **JSON формат tool calls**: Единый структурированный формат вместо regexp
2. **Автоматическое накопление**: Результаты tool calls передаются в следующую итерацию LLM
3. **Умное завершение**: LLM сам определяет когда цепочка tool calls завершена
4. **Детальные ошибки**: При ошибках LLM получает подсказки для исправления
5. **Защита от циклов**: Ограничение на максимальное количество итераций
6. **Полные имена инструментов**: Формат `server_name.tool_name` для точной идентификации

### Следующие шаги для полной интеграции:
- Подключить новый метод к workflow системе
- Протестировать с реальными MCP серверами  
- Добавить конфигурационные параметры

---

## Поддержка многократного взаимодействия в Stage ✅ РЕАЛИЗОВАНО

### Цель
Добавить возможность нескольких итераций взаимодействия пользователя с LLM в рамках одного stage для подтверждения данных и окончательного завершения.

### Этапы реализации

#### 1. Расширение состояния workflow ✅
- [x] Добавить поля в WorkflowState:
  - `stage_iteration: int` - номер итерации в текущем stage
  - `stage_conversation: List[Dict]` - история сообщений в рамках stage
  - `awaiting_confirmation: bool` - флаг ожидания подтверждения
  - `max_stage_iterations: int` - максимальное количество итераций

#### 2. Модификация AgentNode ✅
- [x] Изменить `_execute_stage()` для поддержки циклов
- [x] Добавить проверку `human_input_required` в начале выполнения
- [x] Реализовать логику возврата к пользователю при запросе подтверждения
- [x] Сохранять промежуточные результаты между итерациями
- [x] Добавить метод `process_user_response()` для обработки ответов пользователя

#### 3. Обновление LLM интеграции ✅
- [x] Модифицировать user prompt для включения истории stage
- [x] Добавить инструкции LLM о возможности запроса подтверждения
- [x] Реализовать парсинг ответов LLM на предмет запросов подтверждения
- [x] Добавить специальные команды: `CONFIRM_DATA`, `REQUEST_APPROVAL`, `STAGE_COMPLETE`
- [x] Создать класс `LLMCommandParser` для обработки команд
- [x] Добавить методы `execute_stage_with_iterations()` и `process_user_response_iteration()`

#### 4. Расширение HumanInputNode ✅
- [x] Добавить поддержку контекстных вопросов от LLM
- [x] Реализовать парсинг естественного языка для ответов пользователя
- [x] Добавить возможность отмены/возврата к предыдущему шагу
- [x] Поддержка естественных ответов: "да, подтверждаю", "нет, исправь данные", "измени период на неделю"

#### 5. Обновление workflow engine ✅
- [x] Модифицировать граф для поддержки циклов в stage
- [x] Добавить условные переходы: stage → human_input → stage
- [x] Реализовать логику завершения stage только при явном подтверждении
- [x] Добавить ограничения на количество итераций (защита от бесконечных циклов)
- [x] Обновить `_execute_with_human_loop()` для многоитерационного взаимодействия

#### 6. Улучшение пользовательского интерфейса ✅
- [x] Показывать номер итерации и контекст stage
- [x] Отображать промежуточные результаты LLM
- [x] Принимать естественные ответы пользователя
- [x] Улучшить форматирование вывода для многоэтапных взаимодействий
- [x] Добавить историю взаимодействия в консольный вывод

#### 7. Обработка естественного языка ✅
- [x] Добавить в LLM способность интерпретировать ответы пользователя
- [x] Реализовать классификацию намерений: подтверждение/отклонение/модификация
- [x] Передавать пользовательский ответ обратно в LLM для обработки
- [x] Поддержка сложных запросов: "измени период с 7 на 14 дней и добавь анализ багов"

#### 8. Тестирование ✅
- [x] Создать тестовый workflow с подтверждениями
- [x] Протестировать различные сценарии взаимодействия
- [x] Проверить корректность сохранения состояния между итерациями
- [x] Валидировать ограничения на количество итераций

### Примерный flow ✅
```
Stage Start → LLM Analysis → Request Confirmation ("Данные корректны?") → 
Human Input ("Да, но измени период на 14 дней") → LLM Refinement → 
Request Final Approval ("Готов завершить анализ?") → Human Approval ("Да") → Stage Complete
```

### Технические детали ✅
- [x] Использовать LangGraph conditional edges для циклов
- [x] Сохранять состояние в checkpoints между итерациями  
- [x] Добавить timeout для пользовательского ввода
- [x] Реализовать graceful fallback при отсутствии ответа пользователя

## СТАТУС: РЕАЛИЗОВАНО ✅

Многоитерационное взаимодействие полностью реализовано и протестировано. Система поддерживает:

1. **Специальные команды LLM**: `CONFIRM_DATA`, `REQUEST_APPROVAL`, `STAGE_COMPLETE`
2. **Естественный язык пользователя**: "да, подтверждаю", "нет, исправь", "измени период на 14 дней"
3. **Циклы в stage**: до 5 итераций по умолчанию с защитой от бесконечных циклов
4. **История взаимодействия**: сохранение и отображение контекста разговора
5. **Graceful обработка ошибок**: таймауты, отмена пользователем, лимиты итераций

### Следующие шаги для улучшения:
- [ ] Добавить персистентное сохранение состояния workflow
- [ ] Реализовать веб-интерфейс для многоитерационного взаимодействия
- [ ] Добавить более сложную логику интерпретации естественного языка
- [ ] Создать библиотеку готовых паттернов взаимодействия
